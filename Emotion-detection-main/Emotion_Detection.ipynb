{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://www.dropbox.com/s/htxtli1i6s552r4/dataset.zip?dl=0","metadata":{"id":"iGMZxCkXXdKn","outputId":"3fff6ce8-d92b-48e2-9520-19b113ee0596"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip dataset.zip?dl=0","metadata":{"id":"4V-kwycpXtDJ","outputId":"cadac7c5-947d-4a50-b2d6-eed25ffd6217"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.layers import Flatten, Dense\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator , img_to_array, load_img\nfrom keras.applications.mobilenet import MobileNet, preprocess_input \nfrom keras.losses import categorical_crossentropy","metadata":{"id":"6dcwbXc8Xzww"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Building our Model To train the data ","metadata":{"id":"qQRxQ8qNbvE0"}},{"cell_type":"code","source":"# Working with pre trained model \n\nbase_model = MobileNet( input_shape=(224,224,3), include_top= False )\n\nfor layer in base_model.layers:\n  layer.trainable = False\n\n\nx = Flatten()(base_model.output)\nx = Dense(units=7 , activation='softmax' )(x)\n\n# creating our model.\nmodel = Model(base_model.input, x)","metadata":{"id":"7HCUQigdYELf","outputId":"626e366c-2800-4311-aaa4-77a63ff6b57c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss= categorical_crossentropy , metrics=['accuracy']  )","metadata":{"id":"FN3kEpAeZUGj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing our data using data generator","metadata":{"id":"z6kh9_hjbs47"}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n     zoom_range = 0.2, \n     shear_range = 0.2, \n     horizontal_flip=True, \n     rescale = 1./255\n)\n\ntrain_data = train_datagen.flow_from_directory(directory= \"/content/train\", \n                                               target_size=(224,224), \n                                               batch_size=32,\n                                  )\n\n\ntrain_data.class_indices","metadata":{"id":"fpxBuUAlbmh8","outputId":"82402687-0570-428d-af78-bdaad50444d9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_datagen = ImageDataGenerator(rescale = 1./255 )\n\nval_data = val_datagen.flow_from_directory(directory= \"/content/test\", \n                                           target_size=(224,224), \n                                           batch_size=32,\n                                  )","metadata":{"id":"0x-TwUhocaHn","outputId":"70922d05-e1c1-4eea-9fa9-631bca5dab53"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# visualizaing the data that is fed to train data gen","metadata":{"id":"WNDgYni5c8Qk"}},{"cell_type":"code","source":"# to visualize the images in the traing data denerator \n\nt_img , label = train_data.next()\n\n#-----------------------------------------------------------------------------\n# function when called will prot the images \ndef plotImages(img_arr, label):\n  \"\"\"\n  input  :- images array \n  output :- plots the images \n  \"\"\"\n  count = 0\n  for im, l in zip(img_arr,label) :\n    plt.imshow(im)\n    plt.title(im.shape)\n    plt.axis = False\n    plt.show()\n    \n    count += 1\n    if count == 10:\n      break\n\n#-----------------------------------------------------------------------------\n# function call to plot the images \nplotImages(t_img, label)","metadata":{"id":"5tVIpYKDc2a_","outputId":"c76e7b16-1b3b-4afb-c539-6bf14de8d8c5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# having early stopping and model check point","metadata":{"id":"IhuAjX8KfPa-"}},{"cell_type":"code","source":"## having early stopping and model check point \n\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\n\n# early stopping\nes = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')\n\n# model check point\nmc = ModelCheckpoint(filepath=\"best_model.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n\n# puting call back in a list \ncall_back = [es, mc]","metadata":{"id":"_XtYmjt5dZ2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist = model.fit_generator(train_data, \n                           steps_per_epoch= 10, \n                           epochs= 30, \n                           validation_data= val_data, \n                           validation_steps= 8, \n                           callbacks=[es,mc])","metadata":{"id":"4GxQ9-qSfT3K","outputId":"05e315e5-8f3b-481f-b024-5cbfa5f624ef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Loading the best fit model \nfrom keras.models import load_model\nmodel = load_model(\"/content/best_model.h5\")","metadata":{"id":"V6YSss56fWrD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h =  hist.history\nh.keys()","metadata":{"id":"Rd0p7xDzfe2V","outputId":"852aa271-31b9-4d8d-8ef8-9de03085381a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(h['accuracy'])\nplt.plot(h['val_accuracy'] , c = \"red\")\nplt.title(\"acc vs v-acc\")\nplt.show()","metadata":{"id":"2Qm3Qz11fhMy","outputId":"3a3cdbdd-167c-4368-c675-8b8290d607a9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(h['loss'])\nplt.plot(h['val_loss'] , c = \"red\")\nplt.title(\"loss vs v-loss\")\nplt.show()","metadata":{"id":"f2Z9fjdZfjcU","outputId":"1a92fc5a-71a1-4c89-8fef-e92522f3fbcf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# just to map o/p values \nop = dict(zip( train_data.class_indices.values(), train_data.class_indices.keys()))","metadata":{"id":"2mj02ddxjTyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# path for the image to see if it predics correct class\n\npath = \"/content/test/angry/PrivateTest_1054527.jpg\"\nimg = load_img(path, target_size=(224,224) )\n\ni = img_to_array(img)/255\ninput_arr = np.array([i])\ninput_arr.shape\n\npred = np.argmax(model.predict(input_arr))\n\nprint(f\" the image is of {op[pred]}\")\n\n# to display the image  \nplt.imshow(input_arr[0])\nplt.title(\"input image\")\nplt.show()","metadata":{"id":"8xRgvdZZfltN","outputId":"20dde6d1-1350-4cd7-b671-cd711beeafdc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"woVkimceN8Jr"},"execution_count":null,"outputs":[]}]}